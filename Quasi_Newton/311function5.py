import numpy as np
from numpy import linalg as LA

epsilon = 10 ** -8
N = 1000
Max_LS_iter = 20
mu = 10 ** -4
v = 0.9
y = 10 ** -4

def function(num1, num2, c):
    return ((num1 - 1) ** 2) + ((num2 -1) ** 2) + (c *((num1 ** 2) + (num2 ** 2) - 0.25))

def gradient(num1, num2, c):
    a = ((4 * (num1 ** 3) * c) + (4*c * num1 * (num2 ** 2)) + (2 * num1) - (num1 * c)) - 2
    b = ((4 * (num2 ** 3) * c) + (4*c * (num1 ** 2) * num2) + (2 * num2) - (num2 * c)) - 2
    return np.array([a,b])

def hessian(num1, num2, c):
    a = (12 * (num1 ** 2) * c) + (4 * c * (num2 ** 2)) + 2 - c
    b = 8 * c * num1 * num2
    c = 8 * c * num1 * num2
    d = (12 * (num2 ** 2) * c) + (4 * c * (num1 ** 2)) + 2 - c
    return np.array([[a,b],[c,d]])

def backtracking(mu, p_k, x_k, Max_LS_iter=20):
    n = 0
    alpha = 1
    arg1 = np.add(x_k, (alpha * p_k))
    arg2 = x_k
    while function(arg1[0], arg1[1],c) > (function(arg2[0], arg2[1], c) + (mu * alpha) * np.matmul(np.transpose(gradient(arg2[0], arg2[1], c)), p_k)) and n <= Max_LS_iter:
        alpha = alpha / 2
        n += 1
        print(n)
    return alpha

def quasi(x0,c, epsilon = 10 ** -8, N = 1000, Max_LS_iter = 20, mu = 10 ** -4, v = 0.9, y = 10 ** -4):
    k = 0
    x_k = x0
    b_k = np.identity(2, dtype="float") #acceptable dimensions
    data = [['iteration','function at x_k', 'norm of gradient', 'step size', 'x_k']]
    while k <= N:
        p_k = LA.solve(b_k, (-1 * gradient(x_k[0], x_k[1],c)))
        print("p_k = ", p_k)
        alpha = backtracking(mu, p_k, x_k, Max_LS_iter=20)
        mag_and_direc = alpha * p_k
        x_k1 = np.add(x_k, mag_and_direc)
        print("x_k1 = ", x_k1)
        s_k = np.subtract(x_k1, x_k)
        print("s_k = ", s_k)
        y_k = np.subtract(gradient(x_k1[0], x_k1[1], c), gradient(x_k[0], x_k[1], c))
        print("y_k = ", y_k)
        numerator = np.matmul(np.matmul(b_k, s_k), np.matmul(b_k, s_k).transpose())
        denominator = np.matmul(s_k.transpose(), np.matmul(b_k, s_k))
        a = numerator / denominator
        b = np.matmul(y_k, y_k.transpose()) / np.matmul(y_k.transpose(), s_k)
        print("b =", b)
        ab = a + b
        b_k = np.subtract(b_k, (ab * np.identity(2, dtype="float")))
        x_k = x_k1
        k += 1
        data.append([k, function(x_k[0],x_k[1],c), LA.norm(gradient(x_k[0], x_k[1], c)), alpha, x_k])
    return data

x0 = np.array([1,-1])
c = int(input("Enter C Value: "))
data = quasi(x0,c)
if len(data) > 15:
    a = data[0:11]
    a.extend(data[len(data) - 6:len(data) - 1])
    for item in a:
        print(item)
else:
    for item in data:
        print(item)
#output
# c = 1,
# ['iteration', 'function at x_k', 'norm of gradient', 'step size', 'x_k']
# [1, 5.749961853104651, 13.038254062348027, 4.76837158203125e-07, array([ 0.99999666, -0.99999475])]
# [2, 5.749963396217354, 13.03826016036918, 4.76837158203125e-07, array([ 0.9999968 , -0.99999497])]
# [3, 5.7499649393374455, 13.038266258420832, 4.76837158203125e-07, array([ 0.99999693, -0.99999518])]
# [4, 5.749966482457955, 13.038272356475444, 4.76837158203125e-07, array([ 0.99999707, -0.99999539])]
# [5, 5.749968025578883, 13.038278454533017, 4.76837158203125e-07, array([ 0.9999972, -0.9999956])]
# [6, 5.749969568700228, 13.03828455259355, 4.76837158203125e-07, array([ 0.99999734, -0.99999582])]
# [7, 5.749971111821991, 13.038290650657038, 4.76837158203125e-07, array([ 0.99999747, -0.99999603])]
# [8, 5.749972654944175, 13.038296748723491, 4.76837158203125e-07, array([ 0.99999761, -0.99999624])]
# [9, 5.749974198066774, 13.038302846792899, 4.76837158203125e-07, array([ 0.99999774, -0.99999645])]
# [10, 5.749975741189793, 13.038308944865266, 4.76837158203125e-07, array([ 0.99999788, -0.99999666])]
# [996, 5.751497463985183, 13.044323084457586, 4.76837158203125e-07, array([ 1.00013103, -1.00020588])]
# [997, 5.751499007521003, 13.044329185451556, 4.76837158203125e-07, array([ 1.00013116, -1.00020609])]
# [998, 5.751500551057244, 13.044335286448481, 4.76837158203125e-07, array([ 1.0001313 , -1.00020631])]
# [999, 5.751502094593902, 13.044341387448378, 4.76837158203125e-07, array([ 1.00013143, -1.00020652])]
# [1000, 5.751503638130975, 13.044347488451223, 4.76837158203125e-07, array([ 1.00013157, -1.00020673])]

# c = 10,
# ['iteration', 'function at x_k', 'norm of gradient', 'step size', 'x_k']
# [1, 21.49848559113707, 101.85139033803509, 4.76837158203125e-07, array([ 0.99996662, -0.99996471])]
# [2, 21.498492119238954, 101.85143888503167, 4.76837158203125e-07, array([ 0.99996677, -0.99996487])]
# [3, 21.49849864757597, 101.85148743378467, 4.76837158203125e-07, array([ 0.99996691, -0.99996502])]
# [4, 21.498505175915067, 101.85153598256079, 4.76837158203125e-07, array([ 0.99996705, -0.99996517])]
# [5, 21.498511704256238, 101.85158453136012, 4.76837158203125e-07, array([ 0.9999672 , -0.99996532])]
# [6, 21.498518232599473, 101.85163308018257, 4.76837158203125e-07, array([ 0.99996734, -0.99996547])]
# [7, 21.49852476094479, 101.8516816290282, 4.76837158203125e-07, array([ 0.99996748, -0.99996563])]
# [8, 21.49853128929217, 101.85173017789695, 4.76837158203125e-07, array([ 0.99996763, -0.99996578])]
# [9, 21.49853781764163, 101.85177872678892, 4.76837158203125e-07, array([ 0.99996777, -0.99996593])]
# [10, 21.49854434599316, 101.851827275704, 4.76837158203125e-07, array([ 0.99996792, -0.99996608])]
# [996, 21.504982309153057, 101.89970777660926, 4.76837158203125e-07, array([ 1.00010981, -1.00011608])]
# [997, 21.504988839550435, 101.89975634838746, 4.76837158203125e-07, array([ 1.00010995, -1.00011623])]
# [998, 21.504995369949892, 101.89980492018884, 4.76837158203125e-07, array([ 1.00011009, -1.00011638])]
# [999, 21.505001900351424, 101.89985349201335, 4.76837158203125e-07, array([ 1.00011024, -1.00011654])]
# [1000, 21.505008430755012, 101.89990206386105, 4.76837158203125e-07, array([ 1.00011038, -1.00011669])]

# c = 100
# ['iteration', 'function at x_k', 'norm of gradient', 'step size', 'x_k']
# [1, 178.86478398695544, 991.6925802629473, 4.76837158203125e-07, array([ 0.99966621, -0.99966431])]
# [2, 178.8648426717588, 991.6930529719818, 4.76837158203125e-07, array([ 0.99966636, -0.99966445])]
# [3, 178.86490137708003, 991.6935258463636, 4.76837158203125e-07, array([ 0.9996665, -0.9996646])]
# [4, 178.86496008242008, 991.6939987209716, 4.76837158203125e-07, array([ 0.99966665, -0.99966474])]
# [5, 178.86501878777878, 991.6944715958048, 4.76837158203125e-07, array([ 0.99966679, -0.99966489])]
# [6, 178.86507749315626, 991.6949444708633, 4.76837158203125e-07, array([ 0.99966694, -0.99966504])]
# [7, 178.86513619855248, 991.6954173461473, 4.76837158203125e-07, array([ 0.99966708, -0.99966518])]
# [8, 178.8651949039674, 991.6958902216571, 4.76837158203125e-07, array([ 0.99966723, -0.99966533])]
# [9, 178.865253609401, 991.6963630973921, 4.76837158203125e-07, array([ 0.99966737, -0.99966547])]
# [10, 178.86531231485338, 991.6968359733528, 4.76837158203125e-07, array([ 0.99966752, -0.99966562])]
# [996, 178.92320500517175, 992.1632014070328, 4.76837158203125e-07, array([ 0.99981044, -0.99980936])]
# [997, 178.92326372911248, 992.1636745056003, 4.76837158203125e-07, array([ 0.99981059, -0.99980951])]
# [998, 178.9233224530719, 992.1641476043934, 4.76837158203125e-07, array([ 0.99981073, -0.99980965])]
# [999, 178.92338117705012, 992.164620703412, 4.76837158203125e-07, array([ 0.99981088, -0.9998098 ])]
# [1000, 178.92343990104703, 992.165093802656, 4.76837158203125e-07, array([ 0.99981102, -0.99980994])]